{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Malware Classification Using Machine Learning\n",
        "\n",
        "## Introduction to Malware Analysis\n",
        "\n",
        "Malware represents software specifically designed to cause damage or perform unauthorized actions on computer systems or networks. These malicious programs can be systematically categorized based on their characteristics, operational methods, and intended purposes, among various other factors. A malware category is commonly referred to as a **malware family**. Researchers and security professionals can explore detailed information about different malware families through resources like Malpedia. Notable examples include Emotet and WannaCry, which have gained significant attention in cybersecurity circles.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Malware Classification Methodology\n",
        "\n",
        "### Key Features for Malware Classification\n",
        "\n",
        "When classifying malware, several critical features must be considered to accurately categorize different types of malicious software:\n",
        "\n",
        "- **Behavior and Functionality**: The specific actions and capabilities of the malware\n",
        "- **Delivery and Propagation Methods**: How the malware spreads and infects systems\n",
        "- **Technical Characteristics**: Low-level attributes and implementation details\n",
        "\n",
        "Traditional malware classification requires a comprehensive combination of static and dynamic analysis techniques, including time-intensive reverse engineering of malware binaries. This manual process can be extremely resource-intensive and time-consuming. Therefore, employing machine learning classifiers to assist in malware classification can dramatically accelerate the analysis process while maintaining accuracy.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this section, we will implement a malware classifier based on the innovative technique explored in academic research, which investigates malware classification through the analysis of malware images. This approach represents a novel intersection of computer vision and cybersecurity.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Malware Image Classification Approach\n",
        "\n",
        "### Understanding the Image-Based Classification Method\n",
        "\n",
        "While classifying malware based on images might initially appear counterintuitive, we will explore the dataset in the upcoming sections and discover why this approach proves remarkably effective. The concept leverages the visual representation of binary data to identify patterns and characteristics that distinguish different malware families.\n",
        "\n",
        "For this module, training a classifier on images offers several significant advantages:\n",
        "\n",
        "- **Safety**: We avoid handling potentially dangerous malicious binaries directly\n",
        "- **Security**: By only processing images that represent these binaries, we eliminate the risk of accidentally infecting our system with malware\n",
        "- **Educational Appropriateness**: This approach is more suitable for a learning environment compared to working directly with binary files\n",
        "- **Efficiency**: Image-based analysis can be faster and more scalable than traditional reverse engineering methods\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Convolutional Neural Networks for Malware Classification\n",
        "\n",
        "In the upcoming sections, we will explore the process of training a **Convolutional Neural Network (CNN)** to classify malware images. CNNs are particularly well-suited for this task because they excel at:\n",
        "\n",
        "- **Pattern Recognition**: Identifying visual patterns and textures in image data\n",
        "- **Feature Extraction**: Automatically learning relevant features from raw pixel data\n",
        "- **Hierarchical Learning**: Building complex representations from simple visual elements\n",
        "- **Spatial Relationships**: Understanding the spatial arrangement of features within images\n",
        "\n",
        "This deep learning approach will enable us to automatically discover distinguishing characteristics between different malware families based on their visual representations, providing an efficient and accurate classification system.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Malware Dataset and Data Exploration\n",
        "\n",
        "## Introduction to the Malimg Dataset\n",
        "\n",
        "The dataset of malware images we will be utilizing is the **malimg dataset**, which can be obtained from multiple sources. This dataset was originally proposed in academic research and represents a significant contribution to the field of malware analysis through visual representation.\n",
        "\n",
        "### Dataset Acquisition\n",
        "\n",
        "We can download and unpack the dataset using the following commands:\n",
        "\n",
        "```bash\n",
        "wget https://www.kaggle.com/api/v1/datasets/download/ikrambenabd/malimg-original -O malimg.zip\n",
        "unzip malimg.zip\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset Structure and Organization\n",
        "\n",
        "The dataset consists of **9,339 image files** representing **25 different malware families**. The dataset is organized in folders, where each folder contains all samples for a single malware family. The folder name corresponds to the malware family's name:\n",
        "\n",
        "```bash\n",
        "ls malimg_paper_dataset_imgs\n",
        "\n",
        "Adialer.C        C2LOP.P          Lolyda.AA3      'Swizzor.gen!I'\n",
        "Agent.FYI        Dialplatform.B   Lolyda.AT        VB.AT\n",
        "Allaple.A        Dontovo.A       'Malex.gen!J'     Wintrim.BX\n",
        "Allaple.L        Fakerean         Obfuscator.AD    Yuner.A\n",
        "'Alueron.gen!J'  Instantaccess   'Rbot!gen'\n",
        "Autorun.K        Lolyda.AA1       Skintrim.N\n",
        "'C2LOP.gen!g'    Lolyda.AA2      'Swizzor.gen!E'\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Understanding Malware Image Format\n",
        "\n",
        "Each image contains a visual representation of a **PE (Portable Executable) file**, which is a Windows executable format. The images are grayscale in PNG format.\n",
        "\n",
        "### Binary-to-Image Conversion Process\n",
        "\n",
        "These images represent a direct visualization of the malware binaries. Each pixel in the image corresponds to a single byte in the binary file. The byte can have any value in the 0-255 range, and this exact value is represented by the corresponding pixel's brightness:\n",
        "\n",
        "- **Byte value 0**: Results in a black pixel\n",
        "- **Byte value 255**: Results in a white pixel  \n",
        "- **Values in between**: Result in corresponding gray pixels\n",
        "\n",
        "### Information Preservation\n",
        "\n",
        "Each binary byte is fully encoded within the image, meaning the image can be used to exactly reconstruct the binary without any loss of information. Furthermore, the images can visibly convey patterns in the binary structure.\n",
        "\n",
        "For instance, consider samples from the FakeRean malware family. We can observe distinct patterns in both malware images, demonstrating how visual analysis can reveal structural characteristics of different malware families.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset Exploration and Analysis\n",
        "\n",
        "To familiarize ourselves with the dataset, let's start by creating a plot of the class distribution within it. This enables us to identify classes that are over- or underrepresented, which is crucial for understanding potential biases in our training data.\n",
        "\n",
        "### Required Imports and Setup\n",
        "\n",
        "To achieve this analysis, we will need the following imports as well as a base path to the folder containing the data:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "DATA_BASE_PATH = \"./malimg_paper_dataset_imgs/\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Computing Class Distribution\n",
        "\n",
        "Afterward, we can iterate over all malware families and count the number of images within the corresponding folder to compute the overall class distribution:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# compute the class distribution\n",
        "dist = {}\n",
        "for mlw_class in os.listdir(DATA_BASE_PATH):\n",
        "    mlw_dir = os.path.join(DATA_BASE_PATH, mlw_class)\n",
        "    dist[mlw_class] = len(os.listdir(mlw_dir))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualizing Class Distribution\n",
        "\n",
        "Finally, we can create a barplot to visualize the class distribution using a custom color palette:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot the class distribution\n",
        "\n",
        "# HTB Color Palette\n",
        "htb_green = \"#9FEF00\"\n",
        "node_black = \"#141D2B\"\n",
        "hacker_grey = \"#A4B1CD\"\n",
        "\n",
        "# data\n",
        "classes = list(dist.keys())\n",
        "frequencies = list(dist.values())\n",
        "\n",
        "# plot\n",
        "plt.figure(facecolor=node_black)\n",
        "sns.barplot(y=classes, x=frequencies, edgecolor = \"black\", orient='h', color=htb_green)\n",
        "plt.title(\"Malware Class Distribution\", color=htb_green)\n",
        "plt.xlabel(\"Malware Class Frequency\", color=htb_green)\n",
        "plt.ylabel(\"Malware Class\", color=htb_green)\n",
        "plt.xticks(color=hacker_grey)\n",
        "plt.yticks(color=hacker_grey)\n",
        "ax = plt.gca()\n",
        "ax.set_facecolor(node_black)\n",
        "ax.spines['bottom'].set_color(hacker_grey)\n",
        "ax.spines['top'].set_color(node_black)\n",
        "ax.spines['right'].set_color(node_black)\n",
        "ax.spines['left'].set_color(hacker_grey)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Analysis of Class Distribution\n",
        "\n",
        "From the resulting diagram, we can identify which malware families are represented more than others, potentially skewing the model's performance. The visualization reveals:\n",
        "\n",
        "- **Class Imbalance**: Some families like Allaple.A and Allaple.L have significantly higher frequencies\n",
        "- **Underrepresented Classes**: Other families may have very few samples\n",
        "- **Training Implications**: This imbalance could affect model performance and generalization\n",
        "\n",
        "If the trained model does not provide the expected performance in terms of accuracy, number of false positives, and number of false negatives, we may want to fine-tune the dataset before training to ensure a more balanced class distribution. This could involve techniques such as:\n",
        "\n",
        "- **Data Augmentation**: Creating additional samples for underrepresented classes\n",
        "- **Class Balancing**: Using techniques like SMOTE or undersampling\n",
        "- **Weighted Training**: Adjusting loss functions to account for class imbalance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Preprocessing and Model Architecture\n",
        "\n",
        "## Overview of Data Preprocessing\n",
        "\n",
        "We need to prepare the data before we can feed the images to a CNN for training and inference. In particular, we need to split the data into two distinct datasets: a training and a test set. Furthermore, we need to apply the preprocessing functions expected by our model so the model can work on the images. Lastly, we must create DataLoaders that we can use during training and inference.\n",
        "\n",
        "## Preparing the Datasets\n",
        "\n",
        "To split the data into two distinct datasets, one for training and one for testing, we will use the library `split-folders`, which we can install with pip:\n",
        "\n",
        "```bash\n",
        "pip3 install split-folders\n",
        "```\n",
        "\n",
        "Afterward, we can use the following code to split the data accordingly. We will use an 80-20 split, meaning 80% of the data will be used for training and 20% for testing:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import splitfolders\n",
        "\n",
        "DATA_BASE_PATH = \"./malimg_paper_dataset_imgs/\"\n",
        "TARGET_BASE_PATH = \"./newdata/\"\n",
        "\n",
        "TRAINING_RATIO = 0.8\n",
        "TEST_RATIO = 1 - TRAINING_RATIO\n",
        "\n",
        "splitfolders.ratio(input=DATA_BASE_PATH, output=TARGET_BASE_PATH, ratio=(TRAINING_RATIO, 0, TEST_RATIO))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After running the code once, a new directory `./newdata/` will be created containing three folders:\n",
        "\n",
        "```bash\n",
        "ls -la ./newdata/\n",
        "\n",
        "total 0\n",
        "drwxr-xr-x 1 t t  24 26. Nov 10:52 .\n",
        "drwxr-xr-x 1 t t 160 26. Nov 10:52 ..\n",
        "drwxr-xr-x 1 t t 498 26. Nov 10:52 test\n",
        "drwxr-xr-x 1 t t 498 26. Nov 10:52 train\n",
        "drwxr-xr-x 1 t t 498 26. Nov 10:52 val\n",
        "```\n",
        "\n",
        "The `test` folder contains the test dataset, the `train` folder contains the training dataset, and the `val` folder contains the validation dataset. In this case, we will not use a validation data set, which is why the validation data set is empty. We can confirm the 80-20 split by counting the number of files in each dataset:\n",
        "\n",
        "```bash\n",
        "find ./newdata/test/ -type f | wc -l\n",
        "1880\n",
        "\n",
        "find ./newdata/train/ -type f | wc -l\n",
        "7459\n",
        "\n",
        "find ./newdata/val/ -type f | wc -l\n",
        "0\n",
        "```\n",
        "\n",
        "The split was successful, as we can see. We can now create DataLoaders for training and inference and apply the required preprocessing to the images.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Applying Preprocessing and Creating DataLoaders\n",
        "\n",
        "In the first step, let us define the preprocessing required for our model to read the data. For CNNs, this typically requires a resizing such that all input images are the same size and a normalization. Normalization ensures that the data is standardized before the data is fed to the model. This results in a model that is easier to train. In PyTorch, our preprocessing looks like this:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "# Define preprocessing transforms\n",
        "transform = transforms.Compose([\n",
        "\ttransforms.Resize((75, 75)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Afterward, we can load the datasets from their corresponding folders and apply the preprocessing functions. We need to specify the root folder for each dataset in the `root` parameter and the preprocessing transform in the `transform` parameter. As we have discussed above, the root folders for the datasets are `./newdata/train/` and `./newdata/test/`, respectively.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "import os\n",
        "\n",
        "BASE_PATH = \"./newdata/\"\n",
        "\n",
        "# Load training and test datasets\n",
        "train_dataset = ImageFolder(\n",
        "\troot=os.path.join(BASE_PATH, \"train\"),\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "test_dataset = ImageFolder(\n",
        "\troot=os.path.join(BASE_PATH, \"test\"),\n",
        "    transform=transform\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we can create DataLoader instances, which we can use to iterate over the data for training and inference. We can supply a batch size and specify the number of workers to load the data in the `num_workers` parameter. This enables parallelization and will speed up the data handling:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "TRAIN_BATCH_SIZE = 1024\n",
        "TEST_BATCH_SIZE = 1024\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "\tbatch_size=TRAIN_BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=2\n",
        ")\n",
        "    \n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=TEST_BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=2\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us take a look at one of the preprocessed images to see its effects:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# HTB Color Palette\n",
        "htb_green = \"#9FEF00\"\n",
        "node_black = \"#141D2B\"\n",
        "hacker_grey = \"#A4B1CD\"\n",
        "\n",
        "# image\n",
        "sample = next(iter(train_loader))[0][0]\n",
        "\n",
        "# plot\n",
        "plt.figure(facecolor=node_black)\n",
        "plt.imshow(sample.permute(1,2,0))\n",
        "plt.xticks(color=hacker_grey)\n",
        "plt.yticks(color=hacker_grey)\n",
        "ax = plt.gca()\n",
        "ax.set_facecolor(node_black)\n",
        "ax.spines['bottom'].set_color(hacker_grey)\n",
        "ax.spines['top'].set_color(node_black)\n",
        "ax.spines['right'].set_color(node_black)\n",
        "ax.spines['left'].set_color(hacker_grey)\n",
        "ax.tick_params(axis='x', colors=hacker_grey)\n",
        "ax.tick_params(axis='y', colors=hacker_grey)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is the raw malware image:\n",
        "\n",
        "*[Image of static noise pattern]*\n",
        "\n",
        "This is the resized and normalized image from our DataLoader that we will feed to the model:\n",
        "\n",
        "*[Heatmap visualization with varying shades of blue indicating data intensity]*\n",
        "\n",
        "The details can be roughly discerned from the raw image. However, many of the fine details have been lost.\n",
        "\n",
        "After combining the above code into a single function, we end up with the following code:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "import os\n",
        "\n",
        "def load_datasets(base_path, train_batch_size, test_batch_size):\n",
        "    # Define preprocessing transforms\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((75, 75)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    # Load training and test datasets\n",
        "    train_dataset = ImageFolder(\n",
        "        root=os.path.join(base_path, \"train\"),\n",
        "        transform=transform\n",
        "    )\n",
        "\n",
        "    test_dataset = ImageFolder(\n",
        "        root=os.path.join(base_path, \"test\"),\n",
        "        transform=transform\n",
        "    )\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=train_batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=2\n",
        "    )\n",
        "    \n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=test_batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=2\n",
        "    )\n",
        "\n",
        "    n_classes = len(train_dataset.classes)\n",
        "    return train_loader, test_loader, n_classes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that the function also returns the number of classes in the dataset. As we have mentioned before, the Malimg dataset consists of 25 classes, so we could omit this step and simply assume there are always 25 classes. However, by reading this information dynamically from the data itself, we can use the same code even after making changes to the dataset, either by removing one of the classes or adding new classes to the dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Architecture and Implementation\n",
        "\n",
        "## Overview of the Model\n",
        "\n",
        "The heart of any classifier is the model. As discussed previously, we will be using a CNN model. To speed up the training process, we will base our model on a pre-trained version of a well-established CNN called ResNet50.\n",
        "\n",
        "## ResNet50 Architecture\n",
        "\n",
        "The ResNet family of CNNs was proposed in 2015 in academic research. We will use a variant called ResNet50. This model is 50 layers deep, where it got its name, and consists of roughly 23 million parameters. This model is strong in image classification tasks, which perfectly fits our needs for malware classification.\n",
        "\n",
        "### Transfer Learning Approach\n",
        "\n",
        "To significantly speed up the training process, we will not start with randomly initialized weights but rather with a pre-trained ResNet50 model. Our code will download pre-trained weights and apply them to our model as a baseline. We will then run our training on the malware image dataset to fine-tune it for our purpose. This approach will save us training time in the magnitude of multiple days or even weeks.\n",
        "\n",
        "### Weight Freezing Strategy\n",
        "\n",
        "Furthermore, to further speed up the training process, we will freeze the weights of all ResNet layers except for the final one. Thus, during our training process, only the weights of the final layer will change. While this may reduce our classifier's performance, it will significantly benefit our training time and be a good trade-off for our simple proof-of-concept experiment. We will also adjust the final layer according to our needs. In particular, we may adjust the number of neurons in the final layer and fix the output size to the number of classes in our training data. This results in the following `MalwareClassifier` class:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "HIDDEN_LAYER_SIZE = 1000\n",
        "\n",
        "class MalwareClassifier(nn.Module):\n",
        "    def __init__(self, n_classes):\n",
        "        super(MalwareClassifier, self).__init__()\n",
        "        # Load pretrained ResNet50\n",
        "        self.resnet = models.resnet50(weights='DEFAULT')\n",
        "        \n",
        "        # Freeze ResNet parameters\n",
        "        for param in self.resnet.parameters():\n",
        "            param.requires_grad = False\n",
        "        \n",
        "        # Replace the last fully connected layer\n",
        "        num_features = self.resnet.fc.in_features\n",
        "        self.resnet.fc = nn.Sequential(\n",
        "            nn.Linear(num_features, HIDDEN_LAYER_SIZE),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(HIDDEN_LAYER_SIZE, n_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.resnet(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When initializing the model, we need to specify the number of classes. Since our dataset consists of 25 classes, we can initialize the model like so:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = MalwareClassifier(25)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "However, as discussed in the previous section, the advantage of dynamically setting the number of classes is that we can directly use it from the dataset. By combining the above code with the code from the previous section, we can take the number of classes from the dataset and initialize the model accordingly:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DATA_PATH = \"./newdata/\"\n",
        "TRAINING_BATCH_SIZE = 1024\n",
        "TEST_BATCH_SIZE = 1024\n",
        "\n",
        "# Load datasets\n",
        "train_loader, test_loader, n_classes = load_datasets(DATA_PATH, TRAINING_BATCH_SIZE, TEST_BATCH_SIZE)\n",
        "\n",
        "# Initialize model\n",
        "model = MalwareClassifier(n_classes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Training and Evaluation\n",
        "\n",
        "## Overview of Training and Evaluation Process\n",
        "\n",
        "After loading the datasets and initializing the model, let's finally discuss model training and evaluation to see how well our model performs.\n",
        "\n",
        "## Model Training Implementation\n",
        "\n",
        "Let us define a training function that takes a model, a training loader, and the number of epochs. We will then specify the loss function as `CrossEntropyLoss` and use the Adam optimizer. Afterward, we iterate the entire training data for each epoch and run the forward and backward passes. For a refresher on backpropagation and gradient descent, check out the Fundamentals of AI module.\n",
        "\n",
        "The final training function looks like this:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import time\n",
        "\n",
        "def train(model, train_loader, n_epochs, verbose=False):\n",
        "    model.train()\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "    training_data = {\"accuracy\": [], \"loss\": []}\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        running_loss = 0\n",
        "        n_total = 0\n",
        "        n_correct = 0\n",
        "        checkpoint = time.time() * 1000\n",
        "        \n",
        "        for inputs, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            _, predicted = outputs.max(1)\n",
        "            n_total += labels.size(0)\n",
        "            n_correct += predicted.eq(labels).sum().item()\n",
        "            running_loss += loss.item()\n",
        "        \n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "        epoch_duration = int(time.time() * 1000 - checkpoint)\n",
        "        epoch_accuracy = compute_accuracy(n_correct, n_total)\n",
        "        \n",
        "        training_data[\"accuracy\"].append(epoch_accuracy)\n",
        "        training_data[\"loss\"].append(epoch_loss)\n",
        "        \n",
        "        if verbose:\n",
        "            print(f\"[i] Epoch {epoch+1} of {n_epochs}: Acc: {epoch_accuracy:.2f}% Loss: {epoch_loss:.4f} (Took {epoch_duration} ms).\")    \n",
        "    \n",
        "    return training_data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that much of the code within the training function keeps track of information about the training, such as time elapsed, accuracy, and loss.\n",
        "\n",
        "Additionally, we will define a function to save the trained model to disk for later use:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_model(model, path):\n",
        "\tmodel_scripted = torch.jit.script(model)\n",
        "\tmodel_scripted.save(path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Evaluation\n",
        "\n",
        "To evaluate the model, we will first define a function that runs the model on a single input and returns the predicted class:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict(model, test_data):\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(test_data)\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "\n",
        "    return predicted\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We set the model to evaluation mode using the call `model.eval()` and disable gradient calculation using `torch.no_grad()`. From there, we can write an evaluation function that iterates over the entire test dataset and evaluates the model's performance in terms of accuracy:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_accuracy(n_correct, n_total):\n",
        "    return round(100 * n_correct / n_total, 2)\n",
        "\n",
        "\n",
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "\n",
        "    n_correct = 0\n",
        "    n_total = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            predicted = predict(model, data)\n",
        "            n_total += target.size(0)\n",
        "            n_correct += (predicted == target).sum().item()\n",
        "\n",
        "    accuracy = compute_accuracy(n_correct, n_total)  \n",
        "\n",
        "    return accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization Functions\n",
        "\n",
        "Lastly, let us define a couple of helper functions that create simple plots for the training accuracy and loss per epoch, respectively:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot(data, title, label, xlabel, ylabel):\n",
        "    # HTB Color Palette\n",
        "    htb_green = \"#9FEF00\"\n",
        "    node_black = \"#141D2B\"\n",
        "    hacker_grey = \"#A4B1CD\"\n",
        "\n",
        "    # plot\n",
        "    plt.figure(figsize=(10, 6), facecolor=node_black)\n",
        "    plt.plot(range(1, len(data)+1), data, label=label, color=htb_green)\n",
        "    plt.title(title, color=htb_green)\n",
        "    plt.xlabel(xlabel, color=htb_green)\n",
        "    plt.ylabel(ylabel, color=htb_green)\n",
        "    plt.xticks(color=hacker_grey)\n",
        "    plt.yticks(color=hacker_grey)\n",
        "    ax = plt.gca()\n",
        "    ax.set_facecolor(node_black)\n",
        "    ax.spines['bottom'].set_color(hacker_grey)\n",
        "    ax.spines['top'].set_color(node_black)\n",
        "    ax.spines['right'].set_color(node_black)\n",
        "    ax.spines['left'].set_color(hacker_grey)\n",
        "\n",
        "    legend = plt.legend(facecolor=node_black, edgecolor=hacker_grey, fontsize=10)\n",
        "    plt.setp(legend.get_texts(), color=htb_green)\n",
        "    \n",
        "    plt.show()\n",
        "\n",
        "def plot_training_accuracy(training_data):\n",
        "    plot(training_data['accuracy'], \"Training Accuracy\", \"Accuracy\", \"Epoch\", \"Accuracy (%)\")\n",
        "\n",
        "def plot_training_loss(training_data):\n",
        "    plot(training_data['loss'], \"Training Loss\", \"Loss\", \"Epoch\", \"Loss\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Complete Training and Evaluation Pipeline\n",
        "\n",
        "After defining all helper functions, we can write a script that defines all parameters and runs the helper functions to load the data, initialize the model, train the model, save the model, and finally evaluate the model:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# data parameters\n",
        "DATA_PATH = \"./newdata/\"\n",
        "\n",
        "# training parameters\n",
        "N_EPOCHS = 10\n",
        "TRAINING_BATCH_SIZE = 512\n",
        "TEST_BATCH_SIZE = 1024\n",
        "\n",
        "# model parameters\n",
        "HIDDEN_LAYER_SIZE = 1000\n",
        "MODEL_FILE = \"malware_classifier.pth\"\n",
        "\n",
        "\n",
        "# Load datasets\n",
        "train_loader, test_loader, n_classes = load_datasets(DATA_PATH, TRAINING_BATCH_SIZE, TEST_BATCH_SIZE)\n",
        "\n",
        "# Initialize model\n",
        "model = MalwareClassifier(n_classes)\n",
        "\n",
        "# Train model\n",
        "print(\"[i] Starting Training...\")  \n",
        "training_information = train(model, train_loader, N_EPOCHS, verbose=True)\n",
        "\n",
        "# Save model\n",
        "save_model(model, MODEL_FILE)\n",
        "\n",
        "# evaluate model\n",
        "accuracy = evaluate(model, test_loader)\n",
        "print(f\"[i] Inference accuracy: {accuracy}%.\")  \n",
        "\n",
        "# Plot training details\n",
        "plot_training_accuracy(training_information)\n",
        "plot_training_loss(training_information)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Results and Analysis\n",
        "\n",
        "Running the final code, we can achieve an accuracy of 88.54% on the test dataset:\n",
        "\n",
        "```bash\n",
        "python3 main.py\n",
        "\n",
        "[i] Epoch 1 of 10: Acc: 57.09% Loss: 1.4741 (Took 41128 ms).\n",
        "[i] Epoch 2 of 10: Acc: 85.01% Loss: 0.4631 (Took 40630 ms).\n",
        "[i] Epoch 3 of 10: Acc: 89.60% Loss: 0.2880 (Took 39567 ms).\n",
        "[i] Epoch 4 of 10: Acc: 91.88% Loss: 0.2294 (Took 39464 ms).\n",
        "[i] Epoch 5 of 10: Acc: 92.97% Loss: 0.2113 (Took 39367 ms).\n",
        "[i] Epoch 6 of 10: Acc: 93.86% Loss: 0.1744 (Took 39172 ms).\n",
        "[i] Epoch 7 of 10: Acc: 95.13% Loss: 0.1572 (Took 39804 ms).\n",
        "[i] Epoch 8 of 10: Acc: 94.81% Loss: 0.1501 (Took 39092 ms).\n",
        "[i] Epoch 9 of 10: Acc: 96.51% Loss: 0.1188 (Took 39328 ms).\n",
        "[i] Epoch 10 of 10: Acc: 96.26% Loss: 0.1198 (Took 39125 ms).\n",
        "[i] Inference accuracy: 88.54%.\n",
        "```\n",
        "\n",
        "During the training process, we can observe a steady increase in accuracy up until the final couple of epochs:\n",
        "\n",
        "*[Line graph of training accuracy over epochs, showing an increase from 60% to 95%]*\n",
        "\n",
        "While the final accuracy is not great, it is acceptable, provided our simple training setup. We have tweaked many parameters to favor training time instead of model performance. Keep in mind that the model's accuracy may vary depending on the random split of the datasets. Additionally, tweaking the parameters affects both training time and model performance. Feel free to play around with all the parameters the script defines to determine their effects.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
